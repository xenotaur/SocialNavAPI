{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xenotaur/SocialNavAPI/blob/main/social_nav_api_for_gym_collision_avoidance_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V2 Prototyping the SocialNavAPI for Gym-Collsion-Avoidance\n",
        "\n",
        "This is an attempt to get the Social Nav API from the Principles and Guidelines for Social Navigation paper running with Gym-Collision-Avoidance, defined at:   https://github.com/mit-acl/gym-collision-avoidance"
      ],
      "metadata": {
        "id": "oqksGteboWH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "WMui94CCofBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, gym-collision-avoidance, which is available via pip."
      ],
      "metadata": {
        "id": "19F3SkxYohXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIZhLqPzoQim"
      },
      "outputs": [],
      "source": [
        "!pip install gym-collision-avoidance\n",
        "import gym_collision_avoidance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other required imports for gym-collision-avoidance examples or the Social Nav API."
      ],
      "metadata": {
        "id": "UfX3YHTdpBZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from shapely import geometry\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n"
      ],
      "metadata": {
        "id": "pCJd4r05ocTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test code needed for gym-collision-avoidance examples."
      ],
      "metadata": {
        "id": "4Gtze9lOzfxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gym.logger.set_level(40)\n",
        "os.environ[\"GYM_CONFIG_CLASS\"] = \"Example\"\n",
        "from gym_collision_avoidance.envs import Config\n",
        "from gym_collision_avoidance.envs import test_cases as tc"
      ],
      "metadata": {
        "id": "qh55qov3zlni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Code"
      ],
      "metadata": {
        "id": "Rj0nqcQNzsvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_divider(length=72, character='-'):\n",
        "  print(character * length)\n",
        "\n",
        "def print_message(message, length=72, character='-'):\n",
        "  print_divider(length=length, character=character)\n",
        "  print(character, message, character)\n",
        "  print_divider(length=length, character=character)\n",
        "\n",
        "\n",
        "def raise_bollard(message=\"Forcing stop of execution\"):\n",
        "  print_message(message)\n",
        "  raise RuntimeError(message)\n"
      ],
      "metadata": {
        "id": "-cvAIpg8zvjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Social Nav API"
      ],
      "metadata": {
        "id": "1Y2qlXtBotDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Core Social Nav Wrapper API from the paper."
      ],
      "metadata": {
        "id": "0QNW0q_covCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------\n",
        "# Core wrapper\n",
        "#-----------------------------------------------------\n",
        "class SocialNavWrapper(gym.Wrapper):\n",
        "    def __init__(self, env, metrics):\n",
        "      super().__init__(env)\n",
        "      self.env = env\n",
        "      self.metrics = [metric(self) for metric in metrics]\n",
        "\n",
        "      self.time = 0\n",
        "      self.steps = 0\n",
        "      self.history = []\n",
        "\n",
        "    @property\n",
        "    def state(self):\n",
        "      return self.history[-1] if self.history else None\n",
        "\n",
        "    def reset(self):\n",
        "      self.time = 0\n",
        "      self.steps = 0\n",
        "      self.history = []\n",
        "      return self.env.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "      observation, reward, terminated, truncated, info = self.env.step(action)\n",
        "      self.parse_info(info)\n",
        "      return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def parse_info(self, info):\n",
        "      self.history.append(State.create_from_info(info))\n",
        "      self.time += self.state.timestep\n",
        "      self.steps += 1\n",
        "\n",
        "    def get_metrics(self):\n",
        "      metric_values = {}\n",
        "      for metric in self.metrics:\n",
        "        metric_values.update(metric.compute())\n",
        "      return metric_values\n",
        "\n",
        "    def render(self):\n",
        "        plt.clf()\n",
        "        for pedestrian in self.pedestrians:\n",
        "            plt.scatter(pedestrian.position[0], pedestrian.position[1], color=\"b\")\n",
        "        plt.scatter(self.robot.position[0], self.robot.position[1], color=\"r\")\n",
        "        for obstacle in self.obstacles:\n",
        "            x, y = obstacle.poly.exterior.xy\n",
        "            plt.plot(x, y, color=\"k\")\n",
        "        plt.show(block=False)\n",
        "        plt.pause(0.1)\n",
        "\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# State and info parsing\n",
        "#-----------------------------------------------------\n",
        "class State:\n",
        "  def __init__(self,\n",
        "               robot,\n",
        "               pedestrians,\n",
        "               obstacles,\n",
        "               collisions,\n",
        "               success,\n",
        "               timestep):\n",
        "    self.robot = robot\n",
        "    self.pedestrians = pedestrians\n",
        "    self.obstacles = obstacles\n",
        "    self.collisions = collisions\n",
        "    self.success = success\n",
        "    self.timestep = timestep\n",
        "\n",
        "  @property\n",
        "  def min_distance_to_other_agents(self):\n",
        "    robot_position = self.robot.position\n",
        "    return min([\n",
        "        np.linalg.norm(robot_position - pedestrian.position)\n",
        "        for pedestrian in self.pedestrians\n",
        "        ])\n",
        "\n",
        "  @classmethod\n",
        "  def create_from_info(cls, info):\n",
        "    robot = parse_robot(info)\n",
        "    pedestrians = parse_pedestrians(info)\n",
        "    obstacles = parse_obstacles(info)\n",
        "    collisions = parse_collisions(info)\n",
        "    success = parse_success(info)\n",
        "    timestep = parse_timestep(info)\n",
        "    return cls(\n",
        "        robot=robot,\n",
        "        pedestrians=pedestrians,\n",
        "        obstacles=obstacles,\n",
        "        collisions=collisions,\n",
        "        success=success,\n",
        "        timestep=timestep)\n",
        "\n",
        "def parse_pedestrians(info):\n",
        "    pedestrian_data = info[\"pedestrian_data\"]\n",
        "    pedestrians = []\n",
        "    for data in pedestrian_data:\n",
        "        position = data[\"position\"]\n",
        "        velocity = data[\"velocity\"]\n",
        "        goal = data[\"goal\"]\n",
        "        pedestrians.append(Pedestrian(position, velocity, goal))\n",
        "    return pedestrians\n",
        "\n",
        "def parse_robot(info):\n",
        "    robot_data = info[\"robot_data\"]\n",
        "    return Robot(\n",
        "        position=robot_data[\"position\"],\n",
        "        velocity=robot_data[\"velocity\"],\n",
        "        goal=robot_data[\"goal\"],\n",
        "        shortest_path=robot_data[\"shortest_path\"]\n",
        "    )\n",
        "\n",
        "def parse_obstacles(info):\n",
        "    obstacle_data = info[\"obstacle_data\"]\n",
        "    obstacles = []\n",
        "    for data in obstacle_data:\n",
        "        points = data[\"points\"]\n",
        "        obstacles.append(Obstacle(points))\n",
        "    return obstacles\n",
        "\n",
        "def parse_goal(info):\n",
        "    return info[\"robot_data\"][\"goal\"]\n",
        "\n",
        "def parse_collisions(info):\n",
        "    return info[\"collisions\"]\n",
        "\n",
        "def parse_success(info):\n",
        "    return info[\"success\"]\n",
        "\n",
        "def parse_timestep(info):\n",
        "    return info[\"timestep\"]\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# Robot, pedestrians and obstacles\n",
        "#-----------------------------------------------------\n",
        "class Pedestrian:\n",
        "  def __init__(self, position, velocity, goal):\n",
        "    self.position = np.array(position)\n",
        "    self.velocity = np.array(velocity)\n",
        "    self.goal = np.array(goal)\n",
        "\n",
        "class Robot:\n",
        "  def __init__(self, position, velocity, goal, shortest_path):\n",
        "    self.position = np.array(position)\n",
        "    self.velocity = np.array(velocity)\n",
        "    self.goal = np.array(goal)\n",
        "    self.shortest_path = shortest_path\n",
        "\n",
        "class Obstacle:\n",
        "    def __init__(self, points):\n",
        "        self.poly = geometry.Polygon([[p[0], p[1]] for p in points])\n",
        "\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# Metric Classes\n",
        "#-----------------------------------------------------\n",
        "class Metric:\n",
        "\n",
        "  def __init__(self, env, name, keys=None):\n",
        "    self.name = name\n",
        "    self.env = env\n",
        "    self.keys = keys\n",
        "\n",
        "  def compute(self):\n",
        "    if self.keys:\n",
        "      return {\n",
        "          f\"{self.name}_{key}\": value\n",
        "          for key, value in zip(self.keys, self.value(self.env))\n",
        "      }\n",
        "    else:\n",
        "      return {self.name: self.value(self.env)}\n",
        "\n",
        "  def value(self, env):\n",
        "    pass\n",
        "\n",
        "class SuccessMetric(Metric):\n",
        "\n",
        "  def __init__(self, env, name=\"success\"):\n",
        "    super().__init__(env, name)\n",
        "\n",
        "  def value(self, env):\n",
        "    return env.state.success\n",
        "\n",
        "class DistanceToGoalMetric(Metric):\n",
        "\n",
        "  def __init__(self, env, name=\"distance_to_goal\"):\n",
        "    super().__init__(env, name)\n",
        "\n",
        "  def value(self, env):\n",
        "    return np.linalg.norm(env.state.robot.position - env.state.robot.goal)\n",
        "\n",
        "\n",
        "class CollisionsMetric(Metric):\n",
        "\n",
        "  def __init__(self, env, name=\"collisions\"):\n",
        "    super().__init__(env, name)\n",
        "\n",
        "  def value(self, env):\n",
        "    return env.state.collisions\n",
        "\n",
        "\n",
        "class SplMetric(Metric):\n",
        "\n",
        "  def __init__(self, env, name=\"spl\"):\n",
        "    super().__init__(env, name)\n",
        "\n",
        "  def value(self, env):\n",
        "    if not env.state.success:\n",
        "      return 0\n",
        "    shortest_path = env.state.robot.shortest_path\n",
        "    traversed_distance = traversed_distance(env.history)\n",
        "    return shortest_path / max(shortest_path, traversed_distance)\n",
        "\n",
        "class MinDistanceToOtherAgentsMetric(Metric):\n",
        "\n",
        "  def __init__(self, env, name=\"min_distance_to_other_agents\"):\n",
        "    super().__init__(env, name)\n",
        "\n",
        "  def value(self, env):\n",
        "    return min_distance_to_other_agents(env.history)\n",
        "\n",
        "\n",
        "class JerkMetric(Metric):\n",
        "\n",
        "  def __init__(self, env, name=\"jerk\", keys=(\"min\", \"max\", \"avg\", \"sum\")):\n",
        "    super().__init__(env, name, keys)\n",
        "\n",
        "  def value(self, env):\n",
        "    return get_robot_jerk_stats(env.history)\n",
        "\n",
        "STANDARD_METRICS = [\n",
        "    SplMetric,\n",
        "    SuccessMetric,\n",
        "    CollisionsMetric,\n",
        "    DistanceToGoalMetric,\n",
        "    MinDistanceToOtherAgentsMetric,\n",
        "    JerkMetric\n",
        "]\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# Support Library\n",
        "#-----------------------------------------------------\n",
        "def min_distance_to_other_agents(history):\n",
        "  return min([state.min_distance_to_other_agents for state in history])\n",
        "\n",
        "def get_robot_positions(history):\n",
        "  return np.array([state.robot.position for state in history])\n",
        "\n",
        "def traversed_distance(history):\n",
        "  robot_positions = get_robot_positions(history)\n",
        "  delta_positions = np.diff(robot_positions, axis=0)\n",
        "  delta_distance = np.linalg.norm(delta_positions, axis=1)\n",
        "  return sum(delta_distance)\n",
        "\n",
        "def get_time_deltas(history):\n",
        "  return np.array([state.timestep for state in history])\n",
        "\n",
        "def get_robot_velocities(history):\n",
        "  return np.array([state.robot.velocity for state in history])\n",
        "\n",
        "def get_robot_jerk_history(history):\n",
        "  velocities = get_robot_velocities(history)\n",
        "  velocity_deltas = np.diff(velocities, axis=0)\n",
        "\n",
        "  time_deltas = get_time_deltas(history)\n",
        "  time_broadcast = np.broadcast_to(\n",
        "      np.expand_dims(time_deltas[:-1], 1),\n",
        "      velocity_deltas.shape)\n",
        "\n",
        "  accelerations = velocity_deltas / time_broadcast\n",
        "  acceleration_deltas = np.diff(accelerations, axis=0)\n",
        "\n",
        "  jerk_history = acceleration_deltas / time_broadcast[:-1]\n",
        "  jerk_magnitudes = np.linalg.norm(jerk_history, axis=1)\n",
        "\n",
        "  return jerk_magnitudes, time_deltas[:-2]\n",
        "\n",
        "def get_robot_jerk_stats(history):\n",
        "  jerks, deltas = get_robot_jerk_history(history)\n",
        "  if len(jerks) == 0:\n",
        "    return 0, 0, 0, 0\n",
        "  return jerks.min(), jerks.max(), jerks.mean(), sum(jerks * deltas)\n",
        "\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# GCA Support to generate info\n",
        "#-----------------------------------------------------\n",
        "class GcaWrapperForSocialNav(gym.Wrapper):\n",
        "  def __init__(self, env):\n",
        "    super().__init__(env)\n",
        "    self.env = env\n",
        "    self.action_space = gym.spaces.Dict({\n",
        "        0: gym.spaces.Box(\n",
        "            np.array([0,-1.047]),\n",
        "            np.array([1, 1.047]),\n",
        "            dtype=np.float32)\n",
        "        })\n",
        "    self.robot_index = 0\n",
        "    self.collisions = 0\n",
        "    self.success = False\n",
        "    self.shortest_path_to_goal = None\n",
        "    self.timestep = 0\n",
        "\n",
        "  @property\n",
        "  def robot_agent(self):\n",
        "    return self.agents[self.robot_index]\n",
        "\n",
        "  def step(self, action):\n",
        "    obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "\n",
        "    # Compute relative timestamp\n",
        "    info['timestep'] = self.dt_nominal\n",
        "\n",
        "    # Compute robot position, goal and shortest path length.\n",
        "    # Note that delta positions plus timestamps is enough to get a proxy\n",
        "    # of jerk; the alternative is to compute it from the last action,\n",
        "    # which creates a false value at the start of the episode as you\n",
        "    # have to assume that the agent is starting from zero.\n",
        "    info[\"robot_data\"] = {\n",
        "        \"position\": self.robot_agent.pos_global_frame,\n",
        "        \"velocity\": self.robot_agent.vel_global_frame,\n",
        "        \"goal\": self.robot_agent.goal_global_frame,\n",
        "    }\n",
        "    if self.shortest_path_to_goal is None:\n",
        "      # Cache this as we care about the start of the episode.\n",
        "      # Note this is a slight bug as the shortest path may change if the\n",
        "      # environment is dynamic, so this really can't be computed in step.\n",
        "      self.shortest_path_to_goal = get_shortest_path_to_goal(self.robot_agent)\n",
        "    info[\"robot_data\"][\"shortest_path\"] = self.shortest_path_to_goal\n",
        "\n",
        "    # Compute number of collisons. Note that GCA terminates the episode,\n",
        "    # but we still need to compute the number of collisions for compatibility\n",
        "    # with other environments that may allow more than one collision.\n",
        "    if self.robot_agent.in_collision:\n",
        "      self.collisions = 1  # Since GCA terminates the episode.\n",
        "    info[\"collisions\"] = self.collisions\n",
        "\n",
        "    # Compute success as getting to the goal without collisions.\n",
        "    if self.robot_agent.is_at_goal and not self.robot_agent.in_collision:\n",
        "      self.success = True\n",
        "    info[\"success\"] = self.success\n",
        "\n",
        "    # Compute pedestrian data\n",
        "    pedestrian_data = []\n",
        "    for index, agent in enumerate(self.agents):\n",
        "      if index == self.robot_index:\n",
        "        continue\n",
        "      pedestrian = {\n",
        "        \"position\": agent.pos_global_frame,\n",
        "        \"velocity\": agent.vel_global_frame,\n",
        "        \"goal\": agent.goal_global_frame\n",
        "      }\n",
        "      pedestrian_data.append(pedestrian)\n",
        "    info[\"pedestrian_data\"] = pedestrian_data\n",
        "\n",
        "    # Compute obstacle data ... not supported right now\n",
        "    info[\"obstacle_data\"] = []\n",
        "\n",
        "    # Return the augmented info.\n",
        "    return obs, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "def get_position_from_timeslice(timeslice):\n",
        "  return timeslice[1:3]\n",
        "\n",
        "def get_goal_from_timeslice(timeslice):\n",
        "  return timeslice[3:5]\n",
        "\n",
        "def get_velocity_from_timeslice(timeslice):\n",
        "  return timeslice[7:9]\n",
        "\n",
        "def get_initial_agent_position(agent):\n",
        "  return get_position_from_timeslice(agent.global_state_history[0])\n",
        "\n",
        "def get_initial_agent_goal(agent):\n",
        "  return get_goal_from_timeslice(agent.global_state_history[0])\n",
        "\n",
        "def get_initial_goal_distance(agent):\n",
        "  initial_position = get_initial_agent_position(agent)\n",
        "  initial_goal = get_initial_agent_goal(agent)\n",
        "  return np.linalg.norm(initial_position - initial_goal)\n",
        "\n",
        "def get_shortest_path_to_goal(agent):\n",
        "  # This is an approximation until we get a pathing system.\n",
        "  return get_initial_goal_distance(agent)\n",
        "\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# Example Code\n",
        "#-----------------------------------------------------\n",
        "def social_nav_api_example():\n",
        "    \"\"\"\n",
        "    Minimum working example using social nav API:\n",
        "    2 agents: 1 running external policy, 1 running GA3C-CADRL\n",
        "    \"\"\"\n",
        "\n",
        "    # Create single tf session for all experiments\n",
        "    tf.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "    tf.Session().__enter__()\n",
        "\n",
        "    # Instantiate the environment\n",
        "    env = gym.make(\"CollisionAvoidance-v0\")\n",
        "    env = env.unwrapped # undo all the default wrappers gym applies\n",
        "    env = GcaWrapperForSocialNav(env)\n",
        "    env = SocialNavWrapper(env, metrics=STANDARD_METRICS)\n",
        "\n",
        "    # In case you want to save plots, choose the directory\n",
        "    # abs_path = __file__\n",
        "    abs_path = os.path.abspath('')  # replaces __file__\n",
        "    env.set_plot_save_dir(\n",
        "        os.path.dirname(os.path.realpath(abs_path))\n",
        "        + \"/../../experiments/results/example/\"\n",
        "    )\n",
        "\n",
        "    # Set agent configuration (start/goal pos, radius, size, policy)\n",
        "    agents = tc.get_testcase_two_agents()\n",
        "    [\n",
        "        agent.policy.initialize_network()\n",
        "        for agent in agents\n",
        "        if hasattr(agent.policy, \"initialize_network\")\n",
        "    ]\n",
        "    env.set_agents(agents)\n",
        "\n",
        "    obs = env.reset()  # Get agents' initial observations\n",
        "\n",
        "    # Repeatedly send actions to the environment based on agents' observations\n",
        "    num_steps = 100\n",
        "    for i in range(num_steps):\n",
        "        # Query the external agents' policies\n",
        "        # e.g., actions[0] = external_policy(dict_obs[0])\n",
        "        actions = {}\n",
        "        actions[0] = np.array([1.0, 0.5])\n",
        "\n",
        "        # Internal agents (running a pre-learned policy defined in envs/policies)\n",
        "        # will automatically query their policy during env.step\n",
        "        # ==> no need to supply actions for internal agents here\n",
        "\n",
        "        # Run a simulation step (check for collisions, move sim agents)\n",
        "        obs, rewards, terminated, truncated, info = env.step(actions)\n",
        "\n",
        "        if terminated:\n",
        "            print(\"All agents finished!\")\n",
        "            break\n",
        "        if not i % 10:\n",
        "          print(i)\n",
        "\n",
        "    # Return the environment and info for display\n",
        "    return env, info\n",
        "\n",
        "print_message(\"Example\")\n",
        "env, info = social_nav_api_example()\n",
        "print()\n",
        "\n",
        "print_message(\"Info\")\n",
        "pprint.pprint(info)\n",
        "print()\n",
        "\n",
        "print_message(\"Metrics\")\n",
        "pprint.pprint(env.get_metrics())\n"
      ],
      "metadata": {
        "id": "yXofWcHQouYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czVE4LwYFg9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}